#### 机械式硬盘
- 常见外部存储设备: U盘,光盘,软盘,硬盘,磁带
- 低级格式化: 实现划分磁道,物理属性等
- 高级格式化: 创建文件系统
- 分区:partition 分区用来实现创建独立的文件系统.
- MBR: Master boot Record 或者Main Boot Record;主引导记录.0盘面0磁道0扇区,512字节,不属于任何操作系统;属于全局的,MBR是个扇区
	- 446byte: Bootloader 引导加载器;是一个程序
	- 64byte:每16个字节标识一个分区;也就是分区表
	- 2byte:MagicNumber,标记MBR是否有效
- 硬盘分区是按照柱面分区的
- 现在的MBR是没办法识别2T以上的硬盘空间的,这时候就要使用GPT机制了
    ```
    在生产环境中，我们会遇到分区大于2T的磁盘（比如：添加一个10TB的存储），由于MBR分区表只支持2T磁盘，所以大于2T的磁盘必须使用GPT分区表，而我们在做raid时会划分多个VD来进行装系统，但系统安装完后无法将磁盘全部识别出来，这时就需要手动对GPT分区进行挂载，那么如何在linux中对大于2T的磁盘进行挂载？我将和大家一起分享这一过程：

     GPT格式的磁盘相当于原来MBR磁盘中原来保留4个partition table的4*16个字节,只留第一个16个字节，类似于扩展分区，真正的partition table在512字节之后，GPT磁盘没有四个主分区的限制。

    而fdisk是不支持GPT分区的，我们可以使用parted来对GPT磁盘操作。parted功能很强大，既可用命令行也可以用于交互式，在提示符下输入parted就会进入交互式模式,如果有多个磁盘的话，我们需要运行select sdX（X为磁盘）来进行磁盘的选择，也可直接用parted /dev/sdX指定相应的硬盘。

    [root@server ~]# fdisk -l
    Disk /dev/sda: 21.4 GB, 21474836480 bytes
    255 heads, 63 sectors/track, 2610 cylinders
    Units = cylinders of 16065 * 512 = 8225280 bytes
      Device Boot      Start        End      Blocks  Id  System
    /dev/sda1  *          1          16      128488+  83  Linux
    /dev/sda2              17          49      265072+  82  Linux swap / Solaris
    /dev/sda3              50        2610    20571232+  83  Linux
    Disk /dev/sdb: 2190.4 GB, 2190433320960 bytes
    255 heads, 63 sectors/track, 266305 cylinders
    Units = cylinders of 16065 * 512 = 8225280 bytes
    Disk /dev/sdb doesn't contain a valid partition table
    [root@server ~]# parted
    GNU Parted 1.8.1
    Using /dev/sda
    Welcome to GNU Parted! Type 'help' to view a list of commands.
    (parted) select /dev/sdb              //选择磁盘sdb
    Using /dev/sdb
    (parted) mklabel gpt                  //将MBR磁盘格式化为GPT
    (parted) mkpart primary 0 -1          //将整块磁盘分成一个分区
    (parted) print
    Model: VMware, VMware Virtual S (scsi)
    Disk /dev/sdb: 2190GB
    Sector size (logical/physical): 512B/512B
    Partition Table: gpt
    Number  Start  End    Size    File system  Name    Flags
     1      17.4kB  2190GB  2190GB              primary
    (parted) quit
    Information: Don't forget to update /etc/fstab, if necessary.

    PS：在Linux系统中挂载SCSI盘阵，且分区大小超过2TB时，无法使用mk2fs命令进行格式化，
		而在使用mkfs.ext3命令格式化时，需要增加-T largefile参数，否则格式化过程将非常缓慢，
		对于添加一个10TB的存储，如果linux下直接格式化是一个很漫长的过程，10TB，
		估计少了30小时是完不成的。
    [root@server ~]# mkfs.ext3 -T largefile /dev/sdb1
    赶紧试试把，特步，飞一般的感觉
    [root@server ~]# e2label /dev/sdb1 /data1    //对/dev/sdb1添加（修改）标签为/data1
    [root@server ~]# e2label /dev/sdb1          //查看分区的标签
    /data1
    [root@server ~]# mkdir /data1              //在/分区下创建一个配额的挂载点
    [root@server ~]# mount /dev/sdb1 /data1    //对该分区进行手动挂载
    这样分区完成并挂载成功，用df –h就可以看到该磁盘的大小
    [root@server ~]# df -h
    Filesystem            Size  Used Avail Use% Mounted on
    /dev/sda3              20G  3.9G  15G  22% /
    /dev/sda1            122M  12M  104M  10% /boot
    tmpfs                  62M    0  62M  0% /dev/shm
    /dev/sdb1            2.0T  199M  1.9T  1% /data1
    最后只需在fstab中添加如下一行，就能完成分区的自动挂载
    [root@server ~]# vi /etc/fstab
    /dev/sdb1              /data1                  ext3    defaults        0 0
    ```
- 文件系统:可以理解为一个管理软件,把存储空间划分成两片,一边存储数据的源数据(文件条目inode),另一边是数据存储区域.元数据里有一块叫块位图(bitmap),每一个block都在块位图里有一个标记;同样,inode也有对应的位图.
- 链接文件
	- 硬链接;创建硬链接的时候,源文件和目标文件最好都使用绝对路径;其实硬链接就是指向一个inode的多个不同路径
		- 硬链接只能对文件创建,不能应用于目录
		- 不能跨文件系统,因为inode的引用是不能跨分区的
		- 创建硬链接会增加文件被连接的次数
	- 软连接(符号链接)
		- 可应用于目录
		- 可以跨文件系统
		- 不会增加被连接文件的连接次数
		- 大小为指向的路径所包含的字符个数
	- ln [-s -v] SRC DEST
		- 不加选项,创建硬链接
		- -s:创建软链接
		- -v:显示创建过程
- du:显示文件或者一个目录整体锁占用的磁盘空间大小
	- -s 显示一个目录及其子文件所占用的磁盘空间大小
	- -h humanreadable 显示单位换算
- df:查看整个磁盘分区的使用情况
	- -i 查看inode的使用情况
	- -h humanreadable 显示单位换算
	- -P 在同一行中显示,不换行
	- 不加选项,显示block的使用情况
- du，disk usage,是通过搜索文件来计算每个文件的大小然后累加，du能看到的文件只是一些当前存在的，没有被删除的。他计算的大小就是当前他认为存在的所有文件大小的累加和。df，disk free，通过文件系统来快速获取空间大小的信息，当我们删除一个文件的时候，这个文件不是马上就在文件系统当中消失了，而是暂时消失了，当所有程序都不用时，才会根据OS的规则释放掉已经删除的文件， df记录的是通过文件系统获取到的文件的大小，他比du强的地方就是能够看到已经删除的文件，而且计算大小的时候，把这一部分的空间也加上了，更精确了。当文件系统也确定删除了该文件后，这时候du与df就一致了。
- 设备文件:
	- 块设备:按块为单位,随机访问的设备
		- 硬盘,既是块设备,也是字符设备
	- 字符设备:按字符为单位,线性设备
		- 键盘
		- 硬盘,既是块设备,也是字符设备
	- 当ll /dev的时候,有些文件前面有逗号隔开的两个数字,它们是主设备号和次设备号
		- 主设备号:标识设备类型(Major Number)
		- 次设备号:标识同一种类型中的多个不同的设备(Minor Number).
	- 创建文件设备:mknod [OPTION]... NAME TYPE [MAJOR MINOR]
		- -m MODE 设置权限

	```
	[root@ZhumaTech ~]# mknod -m 640 mydev2 c 66 1
	[root@ZhumaTech ~]# ll
	total 56
	-rw-r--r--. 1 root root    53 Mar 21 15:40 1
	-rw-r--r--. 1 root root     0 Mar  7 12:12 a b
	-rw-------. 1 root root  1039 Nov 10 17:35 anaconda-ks.cfg
	-rwxr-xr-x. 1 root root   140 Mar 20 10:43 debug.sh
	-rw-r--r--. 1 root root   874 Mar  9 09:34 inittab
	-rw-r--r--. 1 root root  9113 Nov 10 17:35 install.log
	-rw-r--r--. 1 root root  3161 Nov 10 17:34 install.log.syslog
	crw-r--r--. 1 root root 66, 0 Mar 21 15:41 mydev
	crw-r-----. 1 root root 66, 1 Mar 21 15:41 mydev2
	-rwxr-xr-x. 1 root root 19688 Mar  9 09:40 rc.sysinit
	-rwxr-xr-x. 1 root root    56 Mar 21 09:36 shift.sh
	```

	- tty命令可以查看本机使用的tty是什么
	- `echo "hello" >> /dev/pts/1` 可以向/dev/pts/1发送hello.___不要轻易的往设备发送信息,如果这个hello是向硬盘发送,会覆盖MBR___
	- 查看当前系统识别了几块硬盘: fdisk -l
	- Linux的支持的文件系统
		- 创建文件系统;高级格式化 mkfs -t(type) ext3
		- 文件系统:文件系统不同,linux上有个程序(动态库)叫vfs(也是内核功能)把下面的文件系统调用接口封装了,所以我们能够使用统一的命令对他们进行操作,比如高级格式化
			- FAT32: linux上叫 vfat
			- NTFS
			- ISO9660
			- CIFS(通用互联网文件系统,windows网上邻居)
			- ext,~2,~3,~4
			- xfs
			- reiserfs
			- jfs
			- nfs
			- ocfs2
			- gfs2
	- 每一个分区都可以使用不同的文件系统,但最终都要归并到根目录下;这个就叫做挂载
####  管理分区:
- fdisk /dev/sda
	- p:显示当前硬件的分区
	- n:创建新分区
		- e:扩展分区
		- p:主分区
	- d:删除一个分区
	- w:保存退出
	- q:不保存退出
	- t:修改分区类型
	- l:显示锁支持的所有类型
- 创建分区,w保存后,系统内核未必能识别.我们可以 cat /proc/patitions 看一下内核识别了哪些分区;此时我们用partprobe(一般用于红帽5,如果提示COMMAND NOT FOUND,则需要安装parted rpm包;红帽6也可以使用partx)让内核重读分区列表
	- block size常见有三种: 1024b;2048b;4096b.
	- super block:超级块;在源数据区用来保存分区中全局信息,包括块组的数量,每个块组中包含多少块,块大小,空闲磁盘块,已用磁盘块,空闲inode,已用inode;如果一个分区的超级块坏了,分区就挂了. 超级块可以有多个备份.
	- 块组描述符表(GDT):当前系统上一共有多少个块组,每个块组从第几个块开始,到第几个块结束.一样,需要备份.
	- 任何分区的第0个块是不能被使用的,名为 boot block引导块,预留出来,用来存放bootloader.多系统互存的时候才会使用到.但系统 的 bootloader存放在MBR中.
	- 每一个块组都分成了:SuperBlock(不是每个块组都有,备份个几份就可以了,一般情况下找的是第0个块组的SuperBlock,如果这个坏了,会自动找下一个,也可以手动修复),GDT(blockGroup Description Table),block Bitmap(块位图),Inode Bitmap(索引节点位图),Inode Table(索引节点表),Data Blocks(数据块)
	- 系统查找/var/a.txt的顺序, /目录是自引用的,先去inode table 找/的inode,根据此inode去找/的块,在这个块里有var这个文件对应的inode号,根据这个inode号,再回到inode table去查找var对应的块,然后在var块里找a.txt的inode号, 再回到inode table查找a.txt的inode,再根据a.txt的inode找到对应的块.
	- 目录其实是一个对应表,是文件的inode,文件名长度,文件类型
	- inode本身也有大小,所以每个分区的inode的个数也是有比例的,根据文件大小来分配.比如每8k留一个inode,然后32K对应一个INODE 等等.
	- inode包含的内容有权限,属主属组,大小,时间戳,直接磁盘块指针,间接磁盘块指针,二级磁盘块指针...
	- ext3 和 ext2的区别: ext 日志文件系统(journal file system);ext3除了数据区,元数据区,外多了一个日志区;存文件顺序由原来的先存inode,再存数据变成了先把inode放到日志区创建,然后开始存数据,存完之后,再把inode转移到元数据区,如果存数据过程中断电,系统检测只要检测日志区就可以了.所以写文件,ext3会比 ext2慢.
	- 当我们临时文件比较多,性能要求比较高,安全性能要求不高时,我们可以使用ext2.
#### 创建文件系统
- 重新创建文件系统会损坏原有文件
	1. 创建好新分区后(cat /proc/partitons;partx /dev/sda)
	2. mkfs:make file System
		- 查看当前系统内核支持哪些文件类型:cat /proc/filesystems
		- -t(type) FSTYPE PARTITION 为指定的分区创建文件系统
		- mkfs -t ext3命令等同于mkfs.ext3
		- mke2fs:专门用来创建管理ext类型的文件
			- -j: journal 直接创建为ext3类型文件
			- -b BLOCKSIZE: block 指定块大小,默认是4096;可用取值为1024,2048或4096
			- -L LABEL:指定分区卷标
			- -m \#: 指定预留给超级管理员用的块数的百分比,默认为5%
			- -i \#: 指定多为少字节的空间创建一个inode,默认为8192,这里给出的数值应该为块大小的2的n次方倍.
			- -N \#: 指定inode个数.
			- -F: 强制创建文件系统
			- -E: 用户指定额外文件系统属性
				- ___stride=阵列chunk(默认64KB)/block块大小的商,可以优化软RAID的性能.
		- blkid /dev/sda5 查看|定位/dev/sda5的文件属性包括(UUID,TYPE和LABEL)

        ```
		[root@localhost ~]# mke2fs -b 1024 -m 3 -L mydata /dev/sda5
        mke2fs 1.41.12 (17-May-2010)
        文件系统标签=mydata
        操作系统:Linux
        块大小=1024 (log=0)
        分块大小=1024 (log=0)
        Stride=0 blocks, Stripe width=0 blocks
        655872 inodes, 10486212 blocks
        314586 blocks (3.00%) reserved for the super user
        第一个数据块=1
        Maximum filesystem blocks=77856768
        1281 block groups
        8192 blocks per group, 8192 fragments per group
        512 inodes per group
        Superblock backups stored on blocks:
        	8193, 24577, 40961, 57345, 73729, 204801, 221185, 401409, 663553,
        	1024001, 1990657, 2809857, 5120001, 5971969

        正在写入inode表: 完成
        Writing superblocks and filesystem accounting information: 完成

        This filesystem will be automatically checked every 32 mounts or
        180 days, whichever comes first.  Use tune2fs -c or -i to override.
        [root@localhost ~]# blkid /dev/sda5
        /dev/sda5: LABEL="mydata" UUID="deb8770e-90cc-441e-8ccf-64c0e4d8fb35" TYPE="ext2"
		```


		- e2label: 用于查看或定义卷标

		```
		[root@ZhumaTech ~]# e2label /dev/sda5
		MYDATA	//查看卷标
		[root@ZhumaTech ~]# e2label /dev/sda5 HELLOWORLD	//新定义一个卷标
		[root@ZhumaTech ~]# e2label /dev/sda5
		HELLOWORLD
		```

	3. 不损害原有数据,将ext2t升级为ext3调整文件系统的相关属性:
		- tune2fs:调整文件系统的相关属性
			- -j: ext2调整为ext3,只能升级不能降级
			- -L: 设定或修改卷标`tune2fs -L "MYDATA" /dev/sda5`
			- -m: 调整预留百分比

            ```
            [root@ZhumaTech ~]# tune2fs -m 2 /dev/sda5 //调整预留百分比为2
            tune2fs 1.41.12 (17-May-2010)
            Setting reserved blocks percentage to 2% (10496 blocks)
            [root@ZhumaTech ~]# fdisk -l /dev/sda5
            Disk /dev/sda5: 2149 MB, 2149726208 bytes
            255 heads, 63 sectors/track, 261 cylinders
            Units = cylinders of 16065 * 512 = 8225280 bytes
            Sector size (logical/physical): 512 bytes / 512 bytes
            I/O size (minimum/optimal): 512 bytes / 512 bytes
            Disk identifier: 0x00000000
            ```

			- -r \#:指定为管理员预留的块数
			- -o:设定默认挂载选项
				- 我们常用的只有acl选项
			- -c \#:指定挂载次数达到\#,进行自检,0或-1表示关闭此功能
			- -i \#:每挂载使用\#天后进行自检,0或-1表示关闭此功能
			- -l:显示超级块中的信息
		- dumpe2fs /dev/sda5:显示/dev/sda5文件系统相关信息(超级详细,包括块组的信息)
			- h:head 只显示超级块信息
		- fsck:检查并修复Linux文件系统
			- -t FSTYPE:指定文件系统类型
			- -a(automatically): 自动修复
		- e2fsck:专门用来修复ext2/ext3文件系统
			- -f:强制检查
			- -p:自动修复
			- -a:也是自动修复
- 挂载:将新的文件系统关联至当前跟文件系统;反之则为卸载
	- mount挂载(不带选项或参数则是显示当前系统已经挂载情况),挂载点下原有文件在挂载完成后会被暂时隐藏,所以挂载时尽可能使用空目录.
	- mount 设备 挂载点
		- 指定设备:
			- 设备文件 /dev/sda5
			- 卷标: LABEL=""
			- UUID: UUID=""
		- 挂载点:"目录"
			- 要求:
				- 此目录没有被其他进程使用
				- 目录必须存在
				- 如果目录中原有文件,原文件将会被暂时隐藏
		- 挂载完成后,要通过挂载点访问
	- mount [options] [-o options] DEVICE MOUNT_POINT
		- -a:all 挂载/etc/fstab文件中指定的所有的文件系统
		- -n:默认情况下,mount每挂载一个设备,都会把挂载的设备信息保存至/etc/mtab文件,使用-n选项,挂载设备时,不把信息写入此文件,__也就是说当mount命令不带参数时,读取的是/etc/mtab文件,但实际上的加载情况一定会输出到/proc/mounts中__.
		- -t FSTYPE:指定正在挂载的文件系统的类型,不使用此选项时,mount会调用blkid命令获取对应文件系统类型
		- -r:只读挂载,挂载光盘时常用此选项
		- -w:读写挂载
		- -o:指定挂载文件系统挂载选项,也即指定文件系统启用的属性,当有多个选项时,用逗号隔开;默认挂载选项:defaults相当于rw, suid, dev, exec, auto,  nouser,  async, relatime
			- async:异步写入,异步的例子:我们写word,都是先保存在内存里,然后再保存到硬盘,假如我们没按保存,突然停电,你懂的;没有特别需要,默认是异步的
			- sync:同步模式,数据可靠性高,但性能很差
			- atime/noatime:文件(包含目录和文件)每访问一次,都会/不会更新一下文件的访问时间,默认情况使用的是atime;ext4fs默认好像是noatime
			- diratime/nodiratime: 目录访问的时间戳,
			- relatime/norelatime: 是否更新文件的mtime和ctime
			- auto/noauto: 设备是不是能使用-a选项自动挂载,默认是auto
			- exec/noexec: 是否支持将文件系统上应用程序运行为进程,比如U盘最好就设置为noexec
			- dev/nodev: 是否支持激活文件系统上的设备文件
			- suid/nosuid: 当挂载的文件系统上有任何SUID的程序时，只要使用nosuid就能够取消设置SUID的功能
			- _netdev: 若一个网络设备ping不到,就不在挂载这个网络设备
			- remount: 重新挂载当前文件系统
			- user/nouser:是否允许普通用户挂载此设备
			- acl: 是否启用此文件系统上的acl功能
			- ro:挂载为只读
			- rw:读写挂载
			- sync:同步写入
			- suid:千万不要给外来设备挂载这个选项.推荐使用nosuid
			- loop:挂载本地回环设备
	- 挂载ISO镜像:mount -o loop /root/CentOS6.0.iso /mnt/cdrom
	- umount 卸载文件系统
	- umount 设备 或者 umount 挂载点就能完成卸载
	    ```
	    umount -lf /DEVICE 强制卸载挂载的设备。
	    ```
	- 查看正在访问指定文件系统的的进程`fuser -v MOUNT_POINT`
	    ```
	    [root@localhost ~]# cd /mnt/cdrom/
        [root@localhost cdrom]# umount /mnt/cdrom/
        umount: /mnt/cdrom: device is busy.
                (In some cases useful info about processes that use
                 the device is found by lsof(8) or fuser(1))
        [root@localhost cdrom]# fuser -v /mnt/cdrom/
                             用户     进程号 权限   命令
        /mnt/cdrom/:         root       2331 ..c.. bash
        ```

	- 卸载注意事项:
		- 挂载的设备没有进程使用
		- 当挂载的设备不能卸载的时候,可能是有人在使用,我们可以用 fuser -v /MOUNT_POINT 来查看谁在使用
- swap分区,交换空间:允许我们内存过载使用;当物理内存满了的时候,系统会将某程序不常用的页框(page frame)移动到硬盘的swap分区.然后当进程又要调用这些页框的时候,系统会再找一个不常用的页框和swap分区里需要用的页框交换一下.就是这个意思.交换空间一般用来应急.
	- 将内存中的数据放到交换分区的过程被称为page out;取回来叫page in.
	- 作为存储空间,CPU的寄存器速度是最快的,访问时间大概是1纳秒;然后是一级缓存或者二级缓存,访问时间大概是10纳秒;内存的访问时间大概是10毫秒.而磁盘访问速度大概是秒级别了.
	- 如果非要建立交换分区,尽量放在靠外的磁道上.
	- free 查看当前系统物理内存和交换空间的使用情况
		- -m: 以兆为单位来显示内存空间的大小
	- buffers:缓冲,避免慢的设备遭受冲击
	- cached:缓存,把慢的设备传输的东西先存起来,反复使用的.
	- 新建交换分区和创建新分区的方法一样.只不过用t选项要把其类型指定为82:swap
	- 然后对新创建的swap分区写入文件系统
		- 创建交换分区: mkswap /dev/sda6
			- -L LABEL:可以设立卷标
	- 挂载交换分区的方法比较独特:
	- swapon /dev/sda6 : 启用/dev/sda6作为交换分区
			- -a:启用所有的定义在/etc/fstab文件中的交换设备
			- -p PRIORITY: 假如有多个交换分区,我们可以指定优先级.
		- swapoff /dev/sda6 : 关闭/dev/sda6作为交换分区- swapon /dev/sda6 : 启用/dev/sda6作为交换分区
			- -a:启用所有的定义在/etc/fstab文件中的交换设备
			- -p PRIORITY: 假如有多个交换分区,我们可以指定优先级.
		- swapoff /dev/sda6 : 关闭/dev/sda6作为交换分区
		```
		// 新建一个分区,并做成交换分区
		[root@localhost ~]# fdisk /dev/sda

        WARNING: DOS-compatible mode is deprecated. It's strongly recommended to
                 switch off the mode (command 'c') and change display units to
                 sectors (command 'u').

        Command (m for help): n //新建分区
        First cylinder (1459-2764, default 1459):
        Using default value 1459
        Last cylinder, +cylinders or +size{K,M,G} (1459-2764, default 2764): +2G

        Command (m for help): t //把sda5的类型换成swap类型
        Partition number (1-5): 5
        Hex code (type L to list codes): 82
        Changed system type of partition 5 to 82 (Linux swap / Solaris)

        Command (m for help): p

        Disk /dev/sda: 128.8 GB, 128849018880 bytes
        255 heads, 63 sectors/track, 15665 cylinders
        Units = cylinders of 16065 * 512 = 8225280 bytes
        Sector size (logical/physical): 512 bytes / 512 bytes
        I/O size (minimum/optimal): 512 bytes / 512 bytes
        Disk identifier: 0x000f0814

           Device Boot      Start         End      Blocks   Id  System
        /dev/sda1   *           1          26      204800   83  Linux
        Partition 1 does not end on cylinder boundary.
        /dev/sda2              26        1332    10485760   83  Linux
        /dev/sda3            1332        1459     1024000   82  Linux swap / Solaris
        /dev/sda4            1459        2764    10486246    5  Extended
        /dev/sda5            1459        1720     2100284+  82  Linux swap / Solaris

        Command (m for help): w //保存
        The partition table has been altered!

        Calling ioctl() to re-read partition table.

        WARNING: Re-reading the partition table failed with error 16: 设备或资源忙.
        The kernel still uses the old table. The new table will be used at
        the next reboot or after you run partprobe(8) or kpartx(8)
        Syncing disks.
        [root@localhost ~]# partx -a /dev/sda   //重新读取分区表
        BLKPG: Device or resource busy
        error adding partition 1
        BLKPG: Device or resource busy
        error adding partition 2
        BLKPG: Device or resource busy
        error adding partition 3
        BLKPG: Device or resource busy
        error adding partition 4
        BLKPG: Device or resource busy
        error adding partition 5

        [root@localhost ~]# mkswap /dev/sda5    //格式化,写入文件系统
        Setting up swapspace version 1, size = 10486208 KiB
        no label, UUID=c0b9fd93-5833-4317-b006-0cb008396945
        [root@localhost ~]# free -m //先以M为单位查看当前交换分区的大小
                     total       used       free     shared    buffers     cached
        Mem:          1869        516       1352          0         34        188
        -/+ buffers/cache:        294       1575
        Swap:          999          0        999

        [root@localhost ~]# swapon /dev/sda5    //打开新建的交换分区
        [root@localhost ~]# free -m //再以M查看现在的交换分区大小
                     total       used       free     shared    buffers     cached
        Mem:          1869        523       1345          0         34        188
        -/+ buffers/cache:        301       1568
        Swap:        11240          0      11240
        [root@localhost ~]# swapoff /dev/sda5   //关闭交换分区/dev/sda5
        [root@localhost ~]# free -m // /dev/sda5已经消失了
                     total       used       free     shared    buffers     cached
        Mem:          1869        516       1352          0         34        188
        -/+ buffers/cache:        294       1575
        Swap:          999          0        999
        ```
- 回环设备:loopback,使用软件来模拟实现硬件(理解)
- 创建一个镜像文件,模拟120G空间,可以当作一个硬盘来用.
	- dd 转换并复制一个文件;dd if=源文件地址(input file) of=目标文件(output file);可以用bs=\# 指定(blocksize)一次复制的字节大小;count=\# 指定复制的个数.
	- dd和copy复制的区别: copy是以文件为单位进行复制的,先把源文件通过vfs读取到内存中,再重新保存到目标文件处;而dd不是以文件为单位,可以理解为它不通过vfs,而是以0101代码复制到目标位置,所以dd的好处是可以只复制文件的一部分;用bs=\# 指定(blocksize)一次复制的字节大小;count=\# 指定复制的个数;seek=\# 表示从新文件的开始跳过去多少个字节,比如`dd if=/dev/zero of=/mnt/a seek=1023 bs=1M count=1 `表示复制/dev/zero去创建一个新文件,创建新文件时跳过1023个bs,再创建1个bs.这样我们df /mnt/a时显示文件大小为1G,但是du /mnt/a时,它只有1M.

	```
	[root@ZhumaTech ~]# dd if=/etc/inittab of=/root/inittab
	1+1 records in
	1+1 records out
	876 bytes (876 B) copied, 0.000205899 s, 4.3 MB/s
	[root@ZhumaTech ~]# cat /root/inittab
	# inittab is only used by upstart for the default runlevel.
	...省略中间部分...
	#   0 - halt (Do NOT set initdefault to this)
	#   1 - Single user mode
	#   2 - Multiuser, without NFS (The same as 3, if you do not have networking)
	#   3 - Full multiuser mode
	#   4 - unused
	#   5 - X11
	#   6 - reboot (Do NOT set initdefault to this)

	id:3:initdefault:
	```

	```
	// dd命令的功能很强大,比如可以备份硬盘的MBR到U盘
	dd if=/dev/sda of=/mnt/usb/mbr.backup bs=521 count=1
	// 反之dd也能恢复MBR
	dd if=/mnt/usb/mbr.backup of=/dev/sda bs=521 count=1
	// 其实cat也行,把cdrom 一个字节一个字节地保存到/root/rhel5.iso
	cat /dev/cdrom > /root/rhel5.iso
	// /dev/zero 泡泡设备,往外吐0;/dev/null 黑洞设备,啥都吞没了.
	```
- 创建一个1G镜像文件,并挂载成交换分区
	```
	[root@ZhumaTech ~]# dd if=/dev/zero of=/var/swapfile bs=1M count=1024	//创建1个1G的镜像文件
	1024+0 records in
	1024+0 records out
	1073741824 bytes (1.1 GB) copied, 6.54707 s, 164 MB/s
	[root@ZhumaTech ~]# ls -lh /var/swapfile 	//查看这个镜像文件的信息
	-rw-r--r--. 1 root root 1.0G Mar 23 11:17 /var/swapfile
	[root@ZhumaTech ~]# mkswap /var/swapfile	//对这个文件创建swap文件系统
	mkswap: /var/swapfile: warning: don't erase bootbits sectors
	        on whole disk. Use -f to force.
	Setting up swapspace version 1, size = 1048572 KiB
	no label, UUID=fb9bf527-f45e-49a6-bc7c-1dcde51ef11b
	[root@ZhumaTech ~]# free -m		//查看现有的内存和交换分区使用情况
	             total       used       free     shared    buffers     cached
	Mem:          1874       1239        634          0         27       1067
	-/+ buffers/cache:        144       1729
	Swap:         1999          0       1999
	[root@ZhumaTech ~]# swapon /var/swapfile 	//挂载镜像交换分区
	[root@ZhumaTech ~]# free -m		//再查看内存和交换分区使用情况
	             total       used       free     shared    buffers     cached
	Mem:          1874       1240        633          0         27       1067
	-/+ buffers/cache:        144       1729
	Swap:         3023          0       3023
	```

- mount挂载的文件系统,在系统重启后会全部失效,要想开机自动挂载,我们就要配置文件系统的配置文件/etc/fstab(file system table)
- OS在初始化时,会自动挂载/etc/fstab中定义的每一个文件系统
- fstab 是使用空格隔开的6个字段.
	- 第一个字段:要挂载的设备,可以用卷标,也可以用UUID,也可以用设备文件来指定
	- 第二个字段:挂载点.
	- 第三个字段:文件系统类型
	- 第四个字段:挂载选项
	- 第五个字段:转储频率:用于定义多久对此文件做一次完全备份,0不备份,1表示每天都备份,2表示每隔一天备份一次...
	- 第六个字段:文件系统检测次序(一般只有根为1,只有根需要先检查,2表示根检查完以后就检查,可以多个文件同时为2;0表示不检查)
- 当挂载的设备不能卸载的时候,可能是有人在使用,我们可以用 fuser -v /MOUNT_POINT 来查看进程正在使用的文件或套接字文件
	- -v:verbose 查看详细信息
	- -k:结束访问文件的进程
	- -m:指定挂载点,一般可以和-k通用

	```
	//我挂载了/dev/sda5到/sda5,然后用另外一个用户访问/sda5
	[root@ZhumaTech ~]# umount /dev/sda5	//卸载不了
	umount: /sda5: device is busy.
        (In some cases useful info about processes that use
         the device is found by lsof(8) or fuser(1))
	[root@ZhumaTech ~]# fuser -km /sda5	//结束访问/sda5的进程,这时候会把访问/sda5的那个用户给踢掉
	/sda5:                2842c
	//然后就可以正常卸载/sda5
	```
#### 硬盘接口模式
- 驱动程序:将cpu发来的逻辑指令转换成设备对应的自身的控制机制.
- 硬盘的接口:其实还是个控制器(Controller),用来翻译硬盘和cpu的彼此的语言
- 适配器(Adapter):和控制器是一样的东西,只不过控制器一般是继承的,适配器一般是非集成的.
- 协议:两个设备之间互相约定好的,彼此认同的格式;双当都遵循的理解某种信号的法则.
- 并行和串行的区别:
	- IDE(ATA):133Mbps;并行
	- SATA(Serial ATA):300Mbps;SATA2:600Mbps;SATA3:6Gbps;串行
	- USB3.0:480Mbps;串行
	- SCSI:Small Computer System Interface,I/O控制器功能特别强大,可以理解为小CPU,当机器的CPU退出的时候,小cpu可以独立指挥,完成后通知大CPU即可,SCSI的硬盘转速也很厉害 15K转,10K转;并行
	- SAS:串行附加存储,SCSI级别的设备
- 当很多用户同时下载文件,且文件各不相同的时候,硬盘就到达了工作能力的上限,这时候我们就可以想办法,组合多个设备来同时完成一个任务;我们在主板上增加一个控制器,它不是用来连接ide,sata,scsi,而是连接另外一个设备,这个设备有特殊接口,这个接口里面能够将一个接口分为多个接口.而这些多个接口可以分别接IDE,SATA,SCSI盘;这个控制器叫做RAID控制器.
- RAID:Redundant Arrays of Inexpensive Disks:廉价冗余磁盘阵列;但是由于要增加特殊的控制器或者适配器,算下来成本并不比SLED(Single Large Expensive Disk独立大容量昂贵的磁盘,多用于工业生产)便宜多少;Inexpensive就被换成了Independent;于是,名字也就变成了独立冗余磁盘阵列.
- 条带技术: 把一个文件分成比较大的单个文件平均分到每一个RAID盘上,而不是传统的1k datablock的轮流存储.
- 根据磁盘组织方式的不同,RAID 有级别之分;RAID LEVEL,级别并不意味着性能的先进,只是表达了磁盘的组合方式不同.
- RAID组合时,不仅要考虑速度,还要考虑数据的可用性(文件损坏的可能性)
	- 磁盘镜像(mirror) 来保证数据的可用性:在每一个RAID子盘上存储同样的数据
	- 校验码:假如有4块盘;系统会把数据平均分配到3块盘上去,留出一块盘,然后存数据的三块盘的校验码放在第四块盘上;比如,第一块存1,第二块存2,第三块存3,在第四块上存的校验码就是1+2+3=6,当存数据的某一块硬盘丢失的时候我们能够推断(假如三块磁盘,就两两做异或运算)出其的数据,也就可以找回数据.坏了两块就GG了.优势是速度和数据可用性得到提升.
- RAID级别,234目前很少用,10和01比较多:
	- 0:条带技术,,把要存储的数据切割成多个块(chunk)在分散到不同的磁盘上去;性能提升,读写速度几乎提升了N倍,但是没有冗余能力(也叫容错,提供多余的来保证可用性);空间利用率n倍(__注意是最小的那块磁盘容量的n倍__);至少需要2块盘
	- 1:镜像,性能表现:读性能提升(可以分开从不同磁盘上读取);写性能下降(同一份数据写两份).冗余能力有提升;空间利用率只有最小那块磁盘容量的大小,至少需要2块盘
	- 2:不常用
	- 3:不常用
	- 4:校验码,风险比较大,因为有一个盘专门用来做校验盘,访问压力较大,很容易成为性能瓶颈;优点是,允许坏一块盘;通常做法是多备一块磁盘做热备,万一哪块盘坏了,这一块就顶上去.然后把坏的换掉,新换上去的就又成为了热备盘
	- 5:轮流做校验码盘,也就是每次轮流有一块盘不存数据用来做校验盘,空间利用率为(n-1)×所有硬盘中最小的容量;性能表现:读写都提升了;冗余能力:有提升.空间利用率(n-1);至少需要3块盘,也是只能坏一块盘
	- 6:用两块盘做循环校验,也就是两块校验盘,空间利用率为(n-2)×所有硬盘中最小的容量;至少4块磁盘很少有人用.
	- 1,0:先两两一组做成RAID1,再把一堆RAID1做成RAID0性能表现:读写都提升了,冗余能力:有提升,空间利用率:1/2;至少需要4块盘,每组镜像最多只能坏一块;__先切割,再做镜像__
	- 0,1:先平均分成两组,每组做成RAID0,然后再把两组做成RAID1.性能表现:读写都提升了,冗余能力:有提升,空间利用率:1/2;至少需要4块盘,__先做镜像,再切割;这个其实并不如1,0好用,因为你分组后,切割方式不一样,坏任意一块盘,很可能全局崩盘__
	- 5,0:性能表现:读写都提升了,冗余能力:有提升,空间利用率:(n-2)/n;至少需要6块盘
    - jbod: Just a Buntch Of Disks. 就是将多块磁盘空间合并成1个大的连续空间使用.性能表现:无提升,冗余能力:无提升,空间利用率:100%;至少需要2块盘;磁盘不一样大也没关系.
- 常见级别: RAID 0, RAID 1,RAID-5,RAID-10, RAID-50,JBOD
- 有钱的企业一般都玩镜像,但是镜像速度太慢,可以镜像条带一起玩;用数字表示:0表示条带,1表示镜像;校验码技术用5来表示;
	- 用三块盘做条带,再用三块盘来做镜像;先做条带,再做镜像,;这个组合就是RAID 0+1
		- 这个当某一个盘坏了的时候影响是全局的,因为做条带的时候元数据盘ABC,和镜像盘A',B',C'中的数据不一定完全一样,假设A盘坏了,我们换了新盘,其修复过程是先从A'B'C'中取出完整的数据,再和BC盘做比较从而得出A盘的数据是什么.
	- 两两组合做镜像,然后再做条带.修复速度和影响范围较上面的好点.这个就是RAID1+0;这个组合如果同组的盘都坏了就GG了.
	- 校验码格式:坏处,校验码盘访问量比其他盘要大,因为任何一个盘的数据访问都要和校验码盘打交道,而它的速度决定了访问其他数据盘的快慢;也就是说校验码盘很容易成为性能瓶颈;解决方案是,让所有盘轮换作为校验码盘;这种轮流做校验码盘的模式就是RAID5.
	- 5,0技术
	- jbod:Just a bunch of disks;磁盘捆绑,把若干个小盘叠加成一个大盘.比如一个500G硬盘来当数据库,数据库文件不断增长快要突破500G了,这时候还不能换盘,还盘业务就中止了;jbod不能提升性能和可用性
- RAID 早期组合IDE和SCSI,现在主要组合SATA和SAS
- SCSI总线分成两类:
	- 窄带:8个接口,适配器(initiator发起点)占一个,还有7个target;而SCSI硬盘容量不大,7个盘未必够用,后来人们又改进了,每个target还可以再分成N个接口,再接N个硬盘进行扩展;在发送数据包的时候要在数据包前面加一个控制信息,指定存在哪个target,哪个盘上,这个控制信息就叫head,首部报文.而每个盘都有自己的标记LUN,logic unit number逻辑单元号码,
	- 宽带:16个接口,适配器(initiator发起点)占一个,还有15个target

##### RAID的实现

###### 硬件RAID;公司里基本上都是这种
- 在服务器上有一个RAID控制芯片用线缆链接到外部存储系统,外部存储系统上有若干块硬盘
- 服务器上的RAID控制芯片连接到SATA接口,然后我们通过BIOS配置启用这个芯片.
- 很可能有些独特的服务器厂商提供的RAID芯片操作系统不能识别,安装过程中必须要额外提供驱动程序.

###### 软件RAID
- Linux内核中有个多磁盘(multi disks)模块;我们可以用md模拟一个RAID,也叫逻辑RAID.
- 逻辑RAID:在设备中表现为 /dev/md\#,注意这个\＃不代表RAID级别,只是表示不同的设备的.
- RAID模式下,磁盘必须要标记为内核可识别的类型:fd;万一系统崩溃了,就特别麻烦,所以一般不推荐使用软RAID.
- 软件RAID需要有md模块和命令mdadm
- mdadm:将任何块设备做成RAID;是一个模式化的命令:
	- 模式
		- -C,--create 创建模式
			- 专用选项:
				- -l:级别
				- -n \#:设备个数
				- -a {yes|no}:是否自动为其创建设备文件;后面要跟上yes|no
				- -c:CHUNK大小,数据块大小必须是2的n次方,默认是64KB
				- -x \#:指定空闲盘个数 注意,-x后面的个数+-n后面的个数必须和 命令最后接的硬盘数是一致的.
		- 管理模式
			- --add
			- -f,--fail,--set-faulty,模拟磁盘损坏
				- 使用方法: mdadm /dev/md\# --fail /dev/sd7
			- --remove
		- -F,--follow,--monitor 监控模式
		- -G,--grow 增长模式
		- -A,--assemble 装配模式
		- -D,--detail 可以查看指定RAID设备的详细信息
		- -S,--stop 停用阵列
		- -D --scan
- 创建2G的RAID0:

    ```
    //1. 先创建两个1G的新分区
    fdisk /dev/sda
    n	//创建新分区
    t	//指定新分区的类型,L可以查看,我们选择fd
    //2. 创建RAIDO
    [root@ZhumaTech ~]# mdadm -C /dev/md0 -a yes -l 0 -n 2 /dev/sda{5,6}
    [root@ZhumaTech ~]# cat /proc/mdstat	//显示当前系统上所有处于启用状态的RAID设备
    //3. 格式化RAID,写入文件系统
    [root@ZhumaTech ~]# mke2fs -j /dev/md0
    //4.查看磁盘分区,就可以看见md0了
    [root@ZhumaTech ~]# fdisk -l
    Disk /dev/md0: 2165 MB, 2165309440 bytes
    2 heads, 4 sectors/track, 528640 cylinders
    Units = cylinders of 8 * 512 = 4096 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 524288 bytes / 1048576 bytes
    Disk identifier: 0x00000000
    //5.挂载md0
    [root@ZhumaTech ~]# mount /dev/md0 /mnt
    ```

- 在管理模式下,可以直接模拟磁盘损坏
	- -f,--fail,--set-faulty,模拟磁盘损坏
	- 使用方法: mdadm /dev/md\# --fail /dev/sd7

	```
	[root@ZhumaTech cdrom]# mdadm /dev/md1 -f /dev/sda8
		mdadm: set /dev/sda8 faulty in /dev/md1
	[root@ZhumaTech cdrom]# mdadm -D /dev/md1
	/dev/md1:
	        Version : 1.2
	  Creation Time : Wed Mar 29 16:52:32 2017
	     Raid Level : raid1
	     Array Size : 1059200 (1034.55 MiB 1084.62 MB)
	  Used Dev Size : 1059200 (1034.55 MiB 1084.62 MB)
	   Raid Devices : 2
	  Total Devices : 2
	    Persistence : Superblock is persistent

	    Update Time : Wed Mar 29 16:55:51 2017
	          State : clean, degraded
	 Active Devices : 1
	Working Devices : 1
	 Failed Devices : 1
	  Spare Devices : 0

           Name : ZhumaTech:1  (local to host ZhumaTech)
           UUID : 6eb3ec1a:e04b907c:30b82221:225fc5ac
         Events : 21

    Number   Major   Minor   RaidDevice State
       0       8        7        0      active sync   /dev/sda7
       1       0        0        1      removed

       1       8        8        -      faulty   /dev/sda8
	```

	- --remove选项可以移除磁盘

	```
	[root@ZhumaTech cdrom]# mdadm /dev/md1 --remove /dev/sda8
	mdadm: hot removed /dev/sda8 from /dev/md1
	```

	- --add 选项可以添加磁盘到RAID阵列

	```
	[root@ZhumaTech cdrom]# mdadm /dev/md1 --add /dev/sda9
	mdadm: added /dev/sda9
	```

- 停止阵列: mdadm -S /dev/md1

  ```
	[root@ZhumaTech cdrom]# mdadm -S /dev/md1
	mdadm: stopped /dev/md1
	```

- 装配阵列: mdadm -A /dev/md1 /dev/sda7 /dev/sda8

	```
	[root@ZhumaTech md]# mdadm -A /dev/md1 /dev/sda{7,8}
	mdadm: /dev/md1 has been started with 1 drive (out of 2).
	```

- 引入新命令watch:周期性地执行指定的命令,并将结果以全屏的方式显示到窗口比如`watch 'COMMAND'`
	- -n \#,指定周期长度,单位为秒.默认为2
- mdadm -D --scan >>/etc/mdadm.conf,mdadm.conf就是主配置文件了,以后就不用再指设备,会主动装配了.

	```
	[root@ZhumaTech md]# mdadm --detail --scan >>/etc/mdadm.conf
	[root@ZhumaTech md]# mdadm -S /dev/md1
	mdadm: stopped /dev/md1
	[root@ZhumaTech md]# mdadm -A /dev/md1	//就不用再指定/dev/sda{7,8}
	mdadm: /dev/md1 has been started with 1 drive (out of 2).
	```

- 列出linux内核总模块状态的程序:lsmod(列出模块)
- MD:Multi Devices;将多个底层的物理设备在内核中抽象出来,在/dev/下提供设备文件,然后通过这个设备访问接口来进行访问,在内核中它的所有调配工作由md这个模块来完成,进而能实现将多个物理设备组合一个所谓的逻辑设备,也有人把它叫做元设备(meta device)
- DM:Device Mapper;设备映射,提供逻辑设备的机制,也能实现多个物理设备映射成一个逻辑设备.功能比MD要强大;DM不仅能够提供RAID功能,还能提供LVM2.功能和MD功能部分重叠.
	- DM是LVM2功能实现的核心
	- snapshot 快照:把数据定格在做快照那一瞬间;快照其实就是访问数据的另外一条路径;快照的主要作用是为了实现数据备份.
	- multipath 多路径
	- DM逻辑设备支持,动态增减
- DM能力,比如我们原有多块物理磁盘,DM可以将它们组织成一个逻辑设备,这个逻辑设备在用户看来就是一个大的设别,当将来这些磁盘都满了,我们可以增加/减少硬盘;注意,DM本身并不能实现文件系统(可以理解为扩展分区),只是一个真正意义上的物理存储融合器,并且能够向上提供一个统一界面,因此我们想要在这里面使用存储数据,我们需要创建类似于逻辑分区.底层的磁盘叫物理卷(phisycal volume);中间的DM 叫VG卷组(Volume Group)相当于扩展分区,上层的逻辑分区部分,叫逻辑卷(Logical Volume);逻辑卷有两种边界:物理边界和逻辑边界(文件系统边界),每一个逻辑卷就是一个独立的文件系统;逻辑卷可以做快照,逻辑卷及其快照卷必须在同一个卷组当中;所以在同一个卷组当中务必要留出空间给其中的某一个逻辑卷创建快照;在PV上,我们把一个物理设备做成PV以后,意味着我们要把它加进一个卷组里去,也就是扩展某一个卷组,只要把PV放进卷组当中,就意味着卷组把这个PV所提供的存储能力划分成一个一个的存储单元(类似RAID的chunk);这些存储单元在这个PV加入到卷组中后,会被事先划分成一个一个块,这个块叫PE(物理盘区,Phisical Extend);只要物理卷加进卷组中以后,一定和卷组锁规定的PE是相同的,也就是说创建卷组的时候会指定多大的PE.因此卷组也就由一大波的PE组成;说白了,逻辑卷的创建也就是;分给一个存储空间一定量的PE;只不过到了逻辑卷的层面上就叫做Logical Extend.扩展逻辑卷的边界,就是添加PE.逻辑卷也支持镜像功能.
- 逻辑卷的实现:
	- 先准备物理卷PV:物理卷可以是磁盘,也可以是分区,还可以是RAID,只要是个块设备就可以.
##### fdisk最多只支持到15个分区;天生的限制.
##### 注意,有的系统是没有安装lvm的,我们要先yum -y install lvm2
- 因此我们要管理的层次就包括管理物理卷,管理卷组,管理逻辑卷;因此管理卷的操作就有;:
	- pv:物理卷:设备类型是8e;RAID是fd
		- pvcreate
		- pvremove:抹掉PV的数据

			```
			[root@ZhumaTech ~]# pvremove /dev/sda10
			 Labels on physical volume "/dev/sda10" successfully wiped
			[root@ZhumaTech ~]# pvs	// /dev/sda10上的数据就全部被抹除了
			  PV         VG   Fmt  Attr PSize PFree
			  /dev/sda9  myvg lvm2 a--  7.01g 7.01g
 			```

			//下面vgreduce的例子中,PV /dev/sda10被从myvg中移除了,我们不需要它了.就可以使用pvremove

			```
			- pvscan:扫描当前系统上一共有多少个PV;比方说我们把当前主机上的PV拆下来,将来放到其他主机上,能够被其他主机识别,就需要先用pvscan扫描一下PV上的元数据把他识别成pv类型
			- pvdisplay: 查看PV的详细信息,pvdisplay /dev/sda9,是只查看PV /dev/sda9的详细信息
			- pvmove:把存了数据的pe转移到其他物理pv上

			```
			//创建10G的pv(我们创建7G+3G;再来5G备用)
			[root@ZhumaTech ~]# fdisk /dev/sda

			WARNING: DOS-compatible mode is deprecated. It's strongly recommended to
			         switch off the mode (command 'c') and change display units to
			         sectors (command 'u').

			Command (m for help): n
			First cylinder (64550-121601, default 64550):
			Using default value 64550
			Last cylinder, +cylinders or +size{K,M,G} (64550-121601, default 121601): +7G

			Command (m for help): n
			First cylinder (65465-121601, default 65465):
			Using default value 65465
			Last cylinder, +cylinders or +size{K,M,G} (65465-121601, default 121601): +3G

			Command (m for help): n
			First cylinder (65858-121601, default 65858):
			Using default value 65858
			Last cylinder, +cylinders or +size{K,M,G} (65858-121601, default 121601): +5G
			// 更改设备类型为8e;RAID底层设备类型为fd; 9,10,11都一样的操作
			Command (m for help): t
			Partition number (1-11): 9(可以用L查看)

			Hex code (type L to list codes): 8e
			Changed system type of partition 9 to 8e (Linux LVM)
			// 保存并partprobe /dev/sda;这里就不操作了
			// 查看分区情况
			[root@ZhumaTech ~]# cat /proc/partitions
			major minor  #blocks  name

			   7        0    4363264 loop0
			   8        0  976762584 sda
			   8        1     204800 sda1
			   8        2  512000000 sda2
			   8        3    2048000 sda3
			   8        4          1 sda4
			   8        5    1055117 sda5
			   8        6    1060258 sda6
			   8        7    1060258 sda7
			   8        8    1060258 sda8
			   8        9    7349706 sda9
			   8       10    3156741 sda10
			   8       11    5253223 sda11
			   9        0    2114560 md0
			   9        1    1059200 md1
			// 有了设备,我们就创建PV. 注意,有的系统是没有安装lvm的,我们要先yum -y install lvm2
			[root@ZhumaTech ~]# pvcreate /dev/sda{9,10}
			Physical volume "/dev/sda9" successfully created
			Physical volume "/dev/sda10" successfully created
			[root@ZhumaTech ~]# pvs	//查看当前系统的PV,pvs查看的是简单信息,更详细的信息可以用pvdisplay
			PV         VG   Fmt  Attr PSize PFree
			/dev/sda10      lvm2 a--  3.01g 3.01g
			/dev/sda9       lvm2 a--  7.01g 7.01g
			[root@ZhumaTech ~]# pvdisplay	//注意此时的PE是没有大小的,在创建成VG卷组以后,就有了;pvdisplay /dev/sda9,是只查看PV /dev/sda9的详细信息
			"/dev/sda9" is a new physical volume of "7.01 GiB"
			--- NEW Physical volume ---
			PV Name               /dev/sda9
			VG Name
			PV Size               7.01 GiB
			Allocatable           NO
			PE Size               0
			Total PE              0
			Free PE               0
			Allocated PE          0
			PV UUID               6RvCT1-G3Ti-guWn-rphL-If88-sunE-qljbTw
			"/dev/sda10" is a new physical volume of "3.01 GiB"
			--- NEW Physical volume ---
			PV Name               /dev/sda10
			VG Name
			PV Size               3.01 GiB
			Allocatable           NO
			PE Size               0
			Total PE              0
			Free PE               0
			Allocated PE          0
			PV UUID               2mf782-WGnO-KcB4-CVDf-6v3t-8DvU-nn5chA
			// 至此,PV创建完成,接下来就是VG相关操作了
			```

	- vg:卷组,命令和PV命令相似
		- vgcreate; 用法: vgcreate VGNAME /dev/sda9 /dev/sda10
			- -s: 此选项可以指定物理盘区(PE)的大小;默认是4M

			```
			[root@ZhumaTech ~]# vgcreate myvg /dev/sda9 /dev/sda10
	 		Volume group "myvg" successfully created	//此时再用pvdisplay就可以看到PE大小了
			[root@ZhumaTech ~]# vgs
			  VG   #PV #LV #SN Attr   VSize  VFree
			  myvg   2   0   0 wz--n- 10.02g 10.02g

			```

		- vgremove: 移除VG 用法为 vgremove VGNAME
		- vgscan
		- vgdisplay

			```
			[root@ZhumaTech ~]# vgdisplay myvg
			  --- Volume group ---
			  VG Name               myvg
			  System ID
			  Format                lvm2
			  Metadata Areas        2
			  Metadata Sequence No  1
			  VG Access             read/write
			  VG Status             resizable
			  MAX LV                0
			  Cur LV                0
			  Open LV               0
			  Max PV                0
			  Cur PV                2
			  Act PV                2
			  VG Size               10.02 GiB
			  PE Size               4.00 MiB
			  Total PE              2564
			  Alloc PE / Size       0 / 0
			  Free  PE / Size       2564 / 10.02 GiB
			  VG UUID               FTaHdE-Te42-i1YW-5TrR-608l-16lx-zefYjw
			```

		- vgmove
		- vgreduce: 我们通过pvs发现我们的myvg卷组里有两个pv,1个7G 一个3G ,我们发现一个7G 就够了,决定移除3G的;缩减VG的过程就是拿掉PV的过程;所以一定要注意在缩减VG前一定要把被移除的PV上的数据移走(pvmove);用法:vgreduce VGNAME /dev/sda10

			```
			[root@ZhumaTech ~]# pvmove /dev/sda10	//我们要移除3G的PV /dev/sda10,所以就要先把它上面的数据移到卷组的其他PV上,这个操作就是.
			No data to move for myvg
			[root@ZhumaTech ~]# vgreduce myvg /dev/sda10	//移除成功
			  Removed "/dev/sda10" from volume group "myvg"
			[root@ZhumaTech ~]# vgs	//vg容量还剩7G
			  VG   #PV #LV #SN Attr   VSize VFree
			  myvg   1   0   0 wz--n- 7.01g 7.01g
			[root@ZhumaTech ~]# pvs	//myvg中还剩下一个PV,就是7G的/dev/sda9
			  PV         VG   Fmt  Attr PSize PFree
			  /dev/sda10      lvm2 a--  3.01g 3.01g
			  /dev/sda9  myvg lvm2 a--  7.01g 7.01g
			```

		- vgextend

			```
			//同样假如我想把那个5G的PV /dev/sda11扩展到我的卷组 myvg
			[root@ZhumaTech ~]# pvcreate /dev/sda11		//先把/dev/sda11 的文件类型设定成pv
	    	Physical volume "/dev/sda11" successfully created
	    	[root@ZhumaTech ~]# vgextend myvg /dev/sda11
			  Volume group "myvg" successfully extended
			[root@ZhumaTech ~]# vgs
			  VG   #PV #LV #SN Attr   VSize  VFree
			  myvg   2   0   0 wz--n- 12.02g 12.02g
			```

	- lv:逻辑卷
		- lvcreate -n LVNAME -L #G VGNAME
			- -n 指定名字
			- -L 指定空间大小(-l 是指定占用 )
		- lvextend
		- lvreduce
		- lvresize
		- lvs
		- lvdisplay

			```
			[root@ZhumaTech ~]# lvcreate -L 50M -n testlv myvg
			  Rounding up size to full physical extent 52.00 MiB
			  Logical volume "testlv" created
			[root@ZhumaTech ~]# lvs
			  LV     VG   Attr       LSize  Pool Origin Data%  Move Log Cpy%Sync Convert
			  testlv myvg -wi-a----- 52.00m
			[root@ZhumaTech ~]# lvdisplay
			  --- Logical volume ---
			  LV Path                /dev/myvg/testlv
			  LV Name                testlv
			  VG Name                myvg
			  LV UUID                N6L2fa-lrOi-CRls-HjeD-R9mI-73PZ-IMyl5b
			  LV Write Access        read/write
			  LV Creation host, time ZhumaTech, 2017-04-05 13:55:16 +0800
			  LV Status              available
			  # open                 0
			  LV Size                52.00 MiB
			  Current LE             13
			  Segments               1
			  Allocation             inherit
			  Read ahead sectors     auto
			  - currently set to     256
			  Block device           253:0

			[root@ZhumaTech ~]# lvdisplay /dev/myvg/testlv
			  --- Logical volume ---
			  LV Path                /dev/myvg/testlv
			  LV Name                testlv
			  VG Name                myvg
			  LV UUID                N6L2fa-lrOi-CRls-HjeD-R9mI-73PZ-IMyl5b
			  LV Write Access        read/write
			  LV Creation host, time ZhumaTech, 2017-04-05 13:55:16 +0800
			  LV Status              available
			  # open                 0
			  LV Size                52.00 MiB
			  Current LE             13
			  Segments               1
			  Allocation             inherit
			  Read ahead sectors     auto
			  - currently set to     256
			  Block device           253:0
			[root@ZhumaTech ~]# mke2fs -j /dev/myvg/testlv //写入文件系统
			mke2fs 1.41.12 (17-May-2010)
			Filesystem label=
			OS type: Linux
			Block size=1024 (log=0)
			Fragment size=1024 (log=0)
			Stride=0 blocks, Stripe width=0 blocks
			13328 inodes, 53248 blocks
			2662 blocks (5.00%) reserved for the super user
			First data block=1
			Maximum filesystem blocks=54525952
			7 block groups
			8192 blocks per group, 8192 fragments per group
			1904 inodes per group
			Superblock backups stored on blocks:
			        8193, 24577, 40961

			Writing inode tables: done
			Creating journal (4096 blocks): done
			Writing superblocks and filesystem accounting information: done

			This filesystem will be automatically checked every 34 mounts or
			180 days, whichever comes first.  Use tune2fs -c or -i to override.
			[root@ZhumaTech ~]# mount /dev/myvg/testlv /mnt //把testlv挂载到/mnt
			[root@ZhumaTech ~]# ls /mnt		//挂载成功了
			lost+found
			[root@ZhumaTech ~]# mount	//查看挂载情况,可以发现挂载的其实是/dev/mapper/myvg-testlv; /dev/myvg/testlv 是它的连接文件
			/dev/sda2 on / type ext4 (rw)
			proc on /proc type proc (rw)
			sysfs on /sys type sysfs (rw)
			devpts on /dev/pts type devpts (rw,gid=5,mode=620)
			tmpfs on /dev/shm type tmpfs (rw,rootcontext="system_u:object_r:tmpfs_t:s0")
			/dev/sda1 on /boot type ext4 (rw)
			/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso on /mnt/cdrom type iso9660 (rw,loop=/dev/loop0)
			none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
			/dev/mapper/myvg-testlv on /mnt type ext3 (rw)
			```

	- lvremove	//处于挂载中的lv是没法移除的;所以要先取消挂载 再移除

		```
		[root@ZhumaTech ~]# umount /dev/myvg/testlv
		[root@ZhumaTech ~]# lvremove /dev/myvg/testlv
		Do you really want to remove active logical volume testlv? [y/n]: y
		  Logical volume "testlv" successfully removed
		```

#### LV高级进阶
##### 扩展逻辑卷
###### 创建分区的过程就是创建物理边界的过程,然后在物理边界内部创建文件系统;而文件系统是位于文件系统边界内的,而这个文件系统边界也被成为逻辑边界;所以到底能存储多少数据既取决于物理边界有多大,也取决于逻辑边界有多大;实际上逻辑边界是紧靠在物理边界上创建的.我们要去扩展一个分区,应该先扩展物理边界,然后再扩展逻辑边界,如果只扩展物理边界,逻辑边界还停留在之前的大小,那么扩展是无意义的;反之,缩减则应先缩减逻辑边界,再缩减物理边界
- 扩展逻辑卷物理边界的命令是lvextend
	- -L [+]\# :举例吧,假设原来的容量是2G 要扩展到5G:lvextend -L +3G /LVNAME(扩展了3G) 等同于 lvextend -L 5G /LVNAME(扩展到5G)
	- 在扩展前务必保证vg的容量是够扩展的.
- 扩展文件系统的边界命令是resize2fs(ext2,ext3文件系统),resize2fs /LVNAME 5G
	- -p 不用指定大小,能扩展到多大就扩展到多大.

	```
	//创建一个2G的lv,并将之扩展到5G
	[root@ZhumaTech ~]# lvcreate -L 2G -n testlv myvg	//在myvg中创建一个2G的名为testlv的逻辑卷
	  Logical volume "testlv" created
	[root@ZhumaTech ~]# mke2fs -j /dev/myvg/testlv	//写入文件系统,文件系统为ext3
	mke2fs 1.41.12 (17-May-2010)
	Filesystem label=
	OS type: Linux
	Block size=4096 (log=2)
	Fragment size=4096 (log=2)
	Stride=0 blocks, Stripe width=0 blocks
	131072 inodes, 524288 blocks
	26214 blocks (5.00%) reserved for the super user
	First data block=0
	Maximum filesystem blocks=536870912
	16 block groups
	32768 blocks per group, 32768 fragments per group
	8192 inodes per group
	Superblock backups stored on blocks:
	        32768, 98304, 163840, 229376, 294912

	Writing inode tables: done
	Creating journal (16384 blocks): done
	Writing superblocks and filesystem accounting information: done

	This filesystem will be automatically checked every 38 mounts or
	180 days, whichever comes first.  Use tune2fs -c or -i to override.
	[root@ZhumaTech ~]# mkdir /users	//创建目录/uers
	[root@ZhumaTech ~]# mount /dev/myvg/testlv /users	//把testlv挂载到/users上
	[root@ZhumaTech ~]# mount	//查看挂载的情况
	/dev/sda2 on / type ext4 (rw)
	proc on /proc type proc (rw)
	sysfs on /sys type sysfs (rw)
	devpts on /dev/pts type devpts (rw,gid=5,mode=620)
	tmpfs on /dev/shm type tmpfs (rw,rootcontext="system_u:object_r:tmpfs_t:s0")
	/dev/sda1 on /boot type ext4 (rw)
	/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso on /mnt/cdrom type iso9660 (rw,loop=/dev/loop0)
	none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
	/dev/mapper/myvg-testlv on /users type ext3 (rw)
	[root@ZhumaTech ~]# cd /users
	[root@ZhumaTech users]# ls
	lost+found
	[root@ZhumaTech users]# cp /etc/inittab .
	[root@ZhumaTech users]# ls
	inittab  lost+found
	[root@ZhumaTech users]# df -lh	//查看testlv的容量大小
	Filesystem                                 Size  Used Avail Use% Mounted on
	/dev/sda2                                  481G   12G  445G   3% /
	tmpfs                                      937M     0  937M   0% /dev/shm
	/dev/sda1                                  194M   27M  158M  15% /boot
	/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso  4.2G  4.2G     0 100% /mnt/cdrom
	/dev/mapper/myvg-testlv                    2.0G   68M  1.9G   4% /users
	[root@ZhumaTech users]# lvextend -L 5G /dev/myvg/testlv 	//将testlv扩展到5G
	  Extending logical volume testlv to 5.00 GiB
	  Logical volume testlv successfully resized
	[root@ZhumaTech users]# df -lh	//这时候查看发现在文件系统中/dev/myvg/testlv还是2G的容量,那是因为我们还没有扩展文件系统边界
	Filesystem                                 Size  Used Avail Use% Mounted on
	/dev/sda2                                  481G   12G  445G   3% /
	tmpfs                                      937M     0  937M   0% /dev/shm
	/dev/sda1                                  194M   27M  158M  15% /boot
	/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso  4.2G  4.2G     0 100% /mnt/cdrom
	/dev/mapper/myvg-testlv                    2.0G   68M  1.9G   4% /users
	[root@ZhumaTech users]# lvs	//但通过lvs可以发现lv的大小在lv管理中已经显示为5G了.
	  LV     VG   Attr       LSize Pool Origin Data%  Move Log Cpy%Sync Convert
	  testlv myvg -wi-ao---- 5.00g
	[root@ZhumaTech users]# resize2fs -p /dev/myvg/testlv //此时,我们来扩展文件系统的边界,用-p选项来做最大的扩容
	resize2fs 1.41.12 (17-May-2010)
	Filesystem at /dev/myvg/testlv is mounted on /users; on-line resizing required
	old desc_blocks = 1, new_desc_blocks = 1
	Performing an on-line resize of /dev/myvg/testlv to 1310720 (4k) blocks.
	The filesystem on /dev/myvg/testlv is now 1310720 blocks long.

	[root@ZhumaTech users]# df -lh	// 此时再查看发现/dev/myvg/testlv 的容量变成了5G
	Filesystem                                 Size  Used Avail Use% Mounted on
	/dev/sda2                                  481G   12G  445G   3% /
	tmpfs                                      937M     0  937M   0% /dev/shm
	/dev/sda1                                  194M   27M  158M  15% /boot
	/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso  4.2G  4.2G     0 100% /mnt/cdrom
	/dev/mapper/myvg-testlv                    5.0G   69M  4.7G   2% /users
	[root@ZhumaTech users]# ls	//之前复制的inittab还是存在的.
	inittab  lost+found
	```

- 扩展一个逻辑卷,并不影响原有文件的使用,并且就算文件系统还在挂载中,也可以直接扩展.非常安全
##### 缩减逻辑卷
- 注意缩减的时候,缩减文件系统边界的时候resize2fs的用法为: resize2fs /PATHTOPV 3G
	1. ___风险非常大,很有可能造成数据丢失,而且,千万不要在线缩减;得先卸载___
	2. ___确保缩减后的空间大小依然能储存原有的所有数据___
	3. ___在缩减之前应强行检查文件,以确保文件系统处于一致性状态:e2fsck -f /dev/myvg/testlv___
- 执行完上面3步以后,再执行resize2fs /PATHTOPV 3G	//将PV缩减到3G
- 然后lvreduce -L [-]\# /PATHTOLV
- 重新挂载

	```
	[root@ZhumaTech users]# cd
	[root@ZhumaTech ~]# df -lh	//查看一下testvg大小
	Filesystem                                 Size  Used Avail Use% Mounted on
	/dev/sda2                                  481G   12G  445G   3% /
	tmpfs                                      937M     0  937M   0% /dev/shm
	/dev/sda1                                  194M   27M  158M  15% /boot
	/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso  4.2G  4.2G     0 100% /mnt/cdrom
	/dev/mapper/myvg-testlv                    5.0G   69M  4.7G   2% /users
	[root@ZhumaTech ~]# umount /users	//卸掉/dev/myvg/testlv的挂载
	[root@ZhumaTech ~]# mount
	/dev/sda2 on / type ext4 (rw)
	proc on /proc type proc (rw)
	sysfs on /sys type sysfs (rw)
	devpts on /dev/pts type devpts (rw,gid=5,mode=620)
	tmpfs on /dev/shm type tmpfs (rw,rootcontext="system_u:object_r:tmpfs_t:s0")
	/dev/sda1 on /boot type ext4 (rw)
	/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso on /mnt/cdrom type iso9660 (rw,loop=/dev/loop0)
	none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
	[root@ZhumaTech ~]# e2fsck -f /dev/myvg/testlv	//强行检测文件系统
	e2fsck 1.41.12 (17-May-2010)
	Pass 1: Checking inodes, blocks, and sizes
	Pass 2: Checking directory structure
	Pass 3: Checking directory connectivity
	Pass 4: Checking reference counts
	Pass 5: Checking group summary information
	/dev/myvg/testlv: 12/327680 files (0.0% non-contiguous), 38000/1310720 blocks
	[root@ZhumaTech ~]# resize2fs /dev/myvg/testlv 3G	//将testlv的文件系统边界缩减到3G
	resize2fs 1.41.12 (17-May-2010)
	Resizing the filesystem on /dev/myvg/testlv to 786432 (4k) blocks.
	The filesystem on /dev/myvg/testlv is now 786432 blocks long.

	[root@ZhumaTech ~]# lvreduce -L 3G /dev/myvg/testlv 	//缩减testlv的物理边界
	  WARNING: Reducing active logical volume to 3.00 GiB
	  THIS MAY DESTROY YOUR DATA (filesystem etc.)
	Do you really want to reduce testlv? [y/n]: y
	  Reducing logical volume testlv to 3.00 GiB
	  Logical volume testlv successfully resized
	[root@ZhumaTech ~]# mount /dev/myvg/testlv /users	//重新挂载
	[root@ZhumaTech ~]# mount	//查看挂载情况
	/dev/sda2 on / type ext4 (rw)
	proc on /proc type proc (rw)
	sysfs on /sys type sysfs (rw)
	devpts on /dev/pts type devpts (rw,gid=5,mode=620)
	tmpfs on /dev/shm type tmpfs (rw,rootcontext="system_u:object_r:tmpfs_t:s0")
	/dev/sda1 on /boot type ext4 (rw)
	/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso on /mnt/cdrom type iso9660 (rw,loop=/dev/loop0)
	none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
	/dev/mapper/myvg-testlv on /users type ext3 (rw)
	[root@ZhumaTech ~]# df -lh	//查看testlv的大小
	Filesystem                                 Size  Used Avail Use% Mounted on
	/dev/sda2                                  481G   12G  445G   3% /
	tmpfs                                      937M     0  937M   0% /dev/shm
	/dev/sda1                                  194M   27M  158M  15% /boot
	/mnt/cdrom/CentOS-6.5-x86_64-bin-DVD1.iso  4.2G  4.2G     0 100% /mnt/cdrom
	/dev/mapper/myvg-testlv                    3.0G   68M  2.8G   3% /users
	[root@ZhumaTech ~]# cd /users
	[root@ZhumaTech users]# cat inittab 	//查看里面的原来的文件是否被损坏
	```

##### 快照卷
- 创建快照卷的命令也是lvcreate;lvcreate -L \# -n SLV_NAME -s -p r /PATHTOLV
	- -s snapshot; 表示创建快着卷
	- -p r|w; Permission
- 注意点:
	1. 生命周期为整个数据访问时长(下面的例子中也就是用来备份数据的),在这段时长内,数据的增长量不能超出快照卷大小;就需要自己估计,安全做法:快照卷和原卷一样大
	2. 快照卷应该是只读的;
	3. 跟原卷在同一卷组内.
	4. 可以在线创建

	```
	[root@ZhumaTech users]# lvcreate -L 50M -n testlv_snap -s -p r /dev/myvg/testlv
	  Rounding up size to full physical extent 52.00 MiB
	  Logical volume "testlv_snap" created
	[root@ZhumaTech users]# lvs
	  LV          VG   Attr       LSize  Pool Origin Data%  Move Log Cpy%Sync Convert
	  testlv      myvg owi-aos---  3.00g
	  testlv_snap myvg sri-a-s--- 52.00m      testlv   0.02
	[root@ZhumaTech users]# mount /dev/myvg/testlv
	testlv       testlv_snap
	[root@ZhumaTech users]# mount /dev/myvg/testlv_snap /mnt/cdrom/
	CentOS_BuildTag                RELEASE-NOTES-en-US.html
	.discinfo                      repodata/
	EFI/                           RPM-GPG-KEY-CentOS-6
	EULA                           RPM-GPG-KEY-CentOS-Debug-6
	GPL                            RPM-GPG-KEY-CentOS-Security-6
	images/                        RPM-GPG-KEY-CentOS-Testing-6
	isolinux/                      TRANS.TBL
	Packages/                      .treeinfo
	[root@ZhumaTech users]# mount /dev/myvg/testlv_snap /mnt/
	mount: block device /dev/mapper/myvg-testlv_snap is write-protected, mounting read-only
	[root@ZhumaTech users]# cd /mnt
	[root@ZhumaTech mnt]# ls
	inittab  lost+found
	//然后可以压缩 或者拷贝出来,这样这个快照卷的生命周期就结束了.
	[root@ZhumaTech /]# umount /mnt
	[root@ZhumaTech /]# lvremove /dev/myvg/testlv_snap
	Do you really want to remove active logical volume testlv_snap? [y/n]: y
	  Logical volume "testlv_snap" successfully removed
	```
